{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 898,
   "id": "a8948d4e-2446-4f9b-90b3-4187e756147c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "id": "4f03bb37-12ce-4e5f-8c21-862b8e78da91",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model = YOLO('CarNumbers_epoch39.pt')\n",
    "#yolo_model.eval()\n",
    "\n",
    "text_model = torch.jit.load('scriped_Number_to_Text_ONLY_BIG.pt')\n",
    "#text_model.eval()\n",
    "\n",
    "#Надо убрать лишние буквы и переобучить модель\n",
    "symbols_keys = {\n",
    "    0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9',\n",
    "    10: 'A', 11: 'B', 12: 'C', 13: 'D', 14: 'E', 15: 'F', 16: 'G', 17: 'H', 18: 'I', 19: 'J',\n",
    "    20: 'K', 21: 'L', 22: 'M', 23: 'N', 24: 'O', 25: 'P', 26: 'Q', 27: 'R', 28: 'S', 29: 'T',\n",
    "    30: 'U', 31: 'V', 32: 'W', 33: 'X', 34: 'Y', 35: 'Z'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "id": "157f1f5b-59b3-47a1-8fd7-a007ae9f4e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_number(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    #cv2.imshow('i', image)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    \n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = yolo_model.predict(image_rgb, conf=0.5)\n",
    "\n",
    "    plates_data = []\n",
    "    if results:\n",
    "        boxes = results[0].boxes.xyxy\n",
    "        #print('\\n\\n',boxes,'\\n\\n')\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.int()\n",
    "            plate_image = image[y1:y2, x1:x2]\n",
    "            #print(plate_image)\n",
    "            plate_image = cv2.cvtColor(plate_image, cv2.COLOR_BGR2GRAY)\n",
    "            plate_image_array = plate_image.astype(np.float32)\n",
    "            plate_image_array /= 255\n",
    "            plates_data.append(plate_image_array)\n",
    "\n",
    "    return plates_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "id": "963332b8-385f-4920-aff6-1747e599587a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 160x640 1 license-plate, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.8ms postprocess per image at shape (1, 3, 160, 640)\n"
     ]
    }
   ],
   "source": [
    "test = detect_number('&.jpg')#А798АР\n",
    "# print(test[1])\n",
    "# cv2.imshow('i', test[0])\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "id": "f9cf593a-b3b3-4a7c-a32a-cac6bb4a1477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Здесь контуризация - не самая лучшая идея\n",
    "# def text_from_numbers(image):\n",
    "#     thresh_value = 100\n",
    "\n",
    "#     image = cv2.resize(image, (256, 45))\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     image_gray = image * 255\n",
    "#     _, thresh = cv2.threshold(image_gray, thresh_value, 255, cv2.THRESH_BINARY_INV)#90\n",
    "    \n",
    "#     cv2.imshow('thresh', thresh)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "    \n",
    "#     thresh = cv2.convertScaleAbs(thresh)\n",
    "#     contours, _ =cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     if contours:\n",
    "#         character_images = []\n",
    "#         _, image_for_NN = cv2.threshold(image*255, thresh_value, 255, cv2.THRESH_BINARY)\n",
    "#         for contour in contours:\n",
    "#             x, y, w, h = cv2.boundingRect(contour)\n",
    "#             if w>10 and h>10:#Попробуй уменьшить и увеличить\n",
    "#                 y_max = y+h\n",
    "#                 x_max = x+w\n",
    "\n",
    "#                 x -= 10 #Может вместо этого добавлять вокруг белые пиксели?\n",
    "#                 y -= 10\n",
    "#                 x_max += 10\n",
    "#                 y_max += 10\n",
    "\n",
    "#                 x = max(0, x)\n",
    "#                 y = max(0, y)\n",
    "#                 x_max = min(x_max, image_for_NN.shape[1]-1)\n",
    "#                 y_max = min(y_max, image_for_NN.shape[0]-1)\n",
    "\n",
    "#                 symbol_for_NN = image_for_NN[y:y_max, x:x_max]\n",
    "#                 #print(image_for_NN)\n",
    "#                 # cv2.imshow('2212.jpg', symbol_for_NN)\n",
    "#                 # cv2.waitKey(0)\n",
    "#                 # cv2.destroyAllWindows()\n",
    "#                 symbol_for_NN = cv2.resize(symbol_for_NN, (28,28))\n",
    "#                 character_images.append(symbol_for_NN)\n",
    "                        \n",
    "#         #print(len(character_images))\n",
    "        \n",
    "#         predicted_chars = []\n",
    "#         for char_image in character_images:\n",
    "#             cv2.imshow('char_image', char_image)\n",
    "#             cv2.waitKey(0)\n",
    "#             cv2.destroyAllWindows()\n",
    "#             char_image_tensor = torch.Tensor(char_image).unsqueeze(0).unsqueeze(0)\n",
    "#             char_image_tensor = char_image_tensor.to(device)\n",
    "#             pred = text_model(char_image_tensor)\n",
    "#             real_char = symbols_keys[pred.argmax().item()]\n",
    "#             print(pred.argmax().item(), real_char,'\\n\\n__________________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "id": "54e32065-99f1-44a8-b321-bfd167a6011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#УЧЕСТЬ, что если ИИ распознает ту часть номера, где буквы, то если она распознает \"0\", то поменять \"0\" на \"О\" и наоборот\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def text_from_numbers(image):\n",
    "    weight = 256\n",
    "    height = 75\n",
    "    image = cv2.resize(image, (weight, height))\n",
    "    #image *= 255\n",
    "    thresh_value = 90\n",
    "    #_, image = cv2.threshold(image*255, thresh_value, 255, cv2.THRESH_BINARY)#90\n",
    "    characters = []\n",
    "    start = 15\n",
    "    step = 27\n",
    "    symb_number = 0\n",
    "    for char in range(start, weight, step):\n",
    "        # if symb_number > 7:\n",
    "        #     break\n",
    "        # if symb_number > 5:\n",
    "        #     symbol = image[:height-17, char:char+step]\n",
    "        # else:\n",
    "        #     symbol = image[:, char:char+step]\n",
    "        symbol = image[:, char:char+step]\n",
    "        symbol = cv2.resize(symbol, (28, 28))\n",
    "        characters.append(symbol)\n",
    "        #print(symbol)\n",
    "        #symb_number+=1\n",
    "    characters = characters[:6]\n",
    "\n",
    "    result = ''\n",
    "    for symb in characters:\n",
    "        # cv2.imshow('symbol', symb)\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "        symb = torch.tensor(symb).unsqueeze(0).unsqueeze(0)\n",
    "        symb = symb.to(device)\n",
    "        pred = text_model(symb)\n",
    "        #print(pred)\n",
    "        real_char = symbols_keys[pred.argmax().item()]\n",
    "        result += real_char\n",
    "        #print(pred.argmax().item(), real_char,'\\n\\n__________________________________________')\n",
    "\n",
    "    print(result)\n",
    "    cv2.imshow('i', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "id": "981e8d7b-d596-4872-bba2-eaecdf0a4a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A798AP\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A798AP'"
      ]
     },
     "execution_count": 904,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_from_numbers(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5de589-268f-44db-9fae-eb11f974005e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15b9acb-9880-4b7d-8d5a-632ab57892cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
